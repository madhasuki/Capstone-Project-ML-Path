{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhasuki/Capstone-Project-ML-Path/blob/main/Porn_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxCD4mGHHjG"
      },
      "source": [
        "## Import All Packages\n",
        "First thing we have to do is import all the packages that we will use later\n",
        "\n",
        "Please take a look at the first code. If you don't have gdown package, you have to install it first. This package help you to download file from google drive. I use this package because i put the dataset in my google drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyBAiKiV9c7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457d330a-dbaa-4fc0-d413-ddbf85b6269a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip install gdown\n",
        "!pip install pyyaml h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DyUfCTgdwa8"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pathlib\n",
        "from google.colab import files\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnxCHHHw9wbF"
      },
      "source": [
        "## Download datasets\n",
        "Download all the datasets from Google Drive. After download the data, we extract them using zipfile package and then we split them into training set and testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df0MX_B-9red"
      },
      "outputs": [],
      "source": [
        "# download the datasets first\n",
        "def download_data(url, output):\n",
        "  gdown.download(url, output, quiet=False)\n",
        "  # after we download the datasets, call the extract funtion to extract the dataset\n",
        "  extract_dataset(output)\n",
        "\n",
        "# this function is to extract dataset\n",
        "def extract_dataset(filename):\n",
        "  local_zip = filename\n",
        "  zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "  zip_ref.extractall()\n",
        "  \n",
        "  zip_ref.close()\n",
        "  os.remove(filename) # remove zip file after extract\n",
        "\n",
        "\n",
        "\n",
        "# download not porn datasets and extract them\n",
        "# download_data('https://drive.google.com/u/4/uc?id=12xtO-msdJ4adT9-ftp1zbmj5ZW99jups', 'not_porn_datasets.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download datasets and extract them, after that we remove zip file\n",
        "download_data('https://drive.google.com/u/0/uc?id=1OU5aZnp1oluBustLBllRt6WG4qCwGVEB', 'datasets.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX2uEMmcBngS",
        "outputId": "6ac35dd6-ceb7-499c-9a5e-bfedac78f13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1OU5aZnp1oluBustLBllRt6WG4qCwGVEB\n",
            "To: /content/datasets.zip\n",
            "100%|██████████| 309M/309M [00:04<00:00, 70.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyrsBrCL902R"
      },
      "source": [
        "Because the not porn data split into several sub folders, we put them into the same folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf0T1X_h95X2"
      },
      "outputs": [],
      "source": [
        "# not_porn_folder ='./not_porn' \n",
        "# not_porn = os.listdir(not_porn_folder) # get all sub directory inside not porn directory\n",
        "# for folder in not_porn:\n",
        "#   sub_folder = os.path.join(not_porn_folder, folder)\n",
        "#   sub_folder_path = os.listdir(sub_folder) # get all data/file from every sub directories \n",
        "#   for file in sub_folder_path:\n",
        "#     old_path = os.path.join(sub_folder, file)\n",
        "#     new_path = os.path.join(not_porn_folder, file)\n",
        "#     shutil.move(old_path, new_path) # move all the data from sub directory into main directory\n",
        "#   os.rmdir(sub_folder) # after we move the data into main directory, we remove the sub directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2TlWiX5986U"
      },
      "source": [
        "Check the amount of data in the porn and not porn directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCSwXT2U-CmV",
        "outputId": "5ffa71c3-a44d-4441-9604-c7e10ae88201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total porn images : 10001\n",
            "total not porn images : 10001\n"
          ]
        }
      ],
      "source": [
        "porn_dir = './porn'\n",
        "not_porn_dir = './not_porn'\n",
        "\n",
        "porn_datasets = os.listdir(porn_dir)\n",
        "not_porn_datasets = os.listdir(not_porn_dir)\n",
        "\n",
        "print('total porn images :', len(porn_datasets))\n",
        "print('total not porn images :', len(not_porn_datasets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZre2h6i-K9y"
      },
      "source": [
        "## Split Data\n",
        "After we download the datasets, we split them into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-QhvSp-N4A"
      },
      "source": [
        "First thing we need to do is create the directory for datasets. We split this directory into 2 sub directory, training and testng, after that we put porn and not porn dataset inside each directory "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45p-ziMF-OrH"
      },
      "outputs": [],
      "source": [
        "# we create the dataset directory first\n",
        "base_dir = './datasets'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'training')\n",
        "testing_dir = os.path.join(base_dir, 'testing')\n",
        "\n",
        "# directory with training porn and not porn picts\n",
        "train_porn_dir = os.path.join(train_dir, 'porn')\n",
        "train_not_porn_dir = os.path.join(train_dir, 'not_porn')\n",
        "\n",
        "# directory with testing porn and not porn picts\n",
        "test_porn_dir = os.path.join(testing_dir, 'porn')\n",
        "test_not_porn_dir = os.path.join(testing_dir, 'not_porn')\n",
        "\n",
        "\n",
        "isExist = os.path.exists(base_dir) #check if directory exist or not\n",
        "\n",
        "if not isExist:\n",
        "  os.makedirs(base_dir) # create datasets directory\n",
        "\n",
        "  os.makedirs(train_dir) #create training directory\n",
        "  os.makedirs(testing_dir) #create testing directory\n",
        "\n",
        "  os.makedirs(train_porn_dir) #create training porn directory\n",
        "  os.makedirs(train_not_porn_dir) #create training not porn directory\n",
        "\n",
        "  os.makedirs(test_porn_dir) #create testing porn directory\n",
        "  os.makedirs(test_not_porn_dir) #create testing not porn directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1q76A_K-U4k"
      },
      "source": [
        "After we create the directory, we move all the datasets from porn and not porn directory into datasets directory.\n",
        "We split them into 5000 pict for training and testing for the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eDebwh5-cL8"
      },
      "outputs": [],
      "source": [
        "def split_data(dataset, old_dir, train_dir, test_dir):\n",
        "  train_data = dataset[:7500]\n",
        "  test_data = dataset[7500:]\n",
        "\n",
        "  move_data(train_data, old_dir, train_dir)\n",
        "  move_data(test_data, old_dir, test_dir)\n",
        "\n",
        "\n",
        "def move_data(data, old_dir, new_dir):\n",
        "  for dt in data:\n",
        "    old_data_path = os.path.join(old_dir, dt)\n",
        "    new_data_path = os.path.join(new_dir, dt)\n",
        "\n",
        "    isExist = os.path.exists(old_data_path)\n",
        "    if isExist:\n",
        "      shutil.move(old_data_path, new_data_path)\n",
        "\n",
        "# move porn file into training set\n",
        "split_data(porn_datasets, porn_dir, train_porn_dir, test_porn_dir)\n",
        "os.rmdir(porn_dir) # remove old porn directory\n",
        "\n",
        "# move not porn file into training set\n",
        "split_data(not_porn_datasets, not_porn_dir, train_not_porn_dir, test_not_porn_dir)\n",
        "os.rmdir(not_porn_dir) # remove old not porn directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWt7Gfwa-gaG"
      },
      "source": [
        "Check the amount of data inside dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bijgo038-hOu",
        "outputId": "4ae150c2-d04c-4f63-f9ce-dd19594439cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total train porn images : 7500\n",
            "total test porn images : 2501\n",
            "\n",
            "total train not porn images : 7500\n",
            "total test not porn images : 2501\n"
          ]
        }
      ],
      "source": [
        "train_porn_sets = os.listdir(train_porn_dir)\n",
        "test_porn_sets = os.listdir(test_porn_dir)\n",
        "\n",
        "train_not_porn_sets = os.listdir(train_not_porn_dir)\n",
        "test_not_porn_sets = os.listdir(test_not_porn_dir)\n",
        "\n",
        "print('total train porn images :', len(train_porn_sets))\n",
        "print('total test porn images :', len(test_porn_sets))\n",
        "\n",
        "print('\\ntotal train not porn images :', len(train_not_porn_sets))\n",
        "print('total test not porn images :', len(test_not_porn_sets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XzNTdPFEGy0"
      },
      "outputs": [],
      "source": [
        "class_names = ['porn', 'not_porn']\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_BdOJIfZ_Q"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWllK_Wad-Mx"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=RMSprop(learning_rate=1e-4),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Zils-4438A"
      },
      "outputs": [],
      "source": [
        "# # Creating Callback Class\n",
        "\n",
        "# class myCallback(tf.keras.callbacks.Callback):\n",
        "#   def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "#     # Check accuracy\n",
        "#     if(logs.get('accuracy') > 0.94):\n",
        "\n",
        "#       # Stop if threshold is met\n",
        "#       print(\"\\nStop Training !!!\")\n",
        "#       self.model.stop_training = True\n",
        "\n",
        "# # Instantiate class\n",
        "# callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK7_Fflgv8YC",
        "outputId": "492dadac-1fd5-45b2-aaed-57dd2fce78f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14998 images belonging to 2 classes.\n",
            "Found 5002 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=100,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        testing_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=100,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQROTQnI-7tQ"
      },
      "outputs": [],
      "source": [
        "# Constant for epochs\n",
        "EPOCHS = 100\n",
        "\n",
        "# Create new model\n",
        "# model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_path = \"training_1/cp.ckpt\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# # Create a callback that saves the model's weights\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                  save_weights_only=True,\n",
        "#                                                  verbose=1)\n",
        "model.summary()\n",
        "# Train the model with the new callback\n",
        "# history = model.fit(\n",
        "#       train_generator,\n",
        "#       steps_per_epoch=150,\n",
        "#       epochs=EPOCHS,\n",
        "#       validation_data=validation_generator,\n",
        "#       validation_steps=50,\n",
        "#       verbose=2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YM7T54HK-c9",
        "outputId": "e51b8bad-3936-4ac1-fe00-9aaeb2d4cb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./myModel.h5')\n",
        "!zip -r ./PornRecognition.zip ./myModel/\n",
        "files.download('./PornRecognition.zip')"
      ],
      "metadata": {
        "id": "VVc1rGnKLCIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_M3zFI5Lvh"
      },
      "source": [
        "## Export and Saved model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQWKkT694_bj"
      },
      "outputs": [],
      "source": [
        "# Export the model\n",
        "export_dir = 'saved_model/1'\n",
        "\n",
        "tf.saved_model.save(model, export_dir)\n",
        "optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.optimizations = [optimization]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('./model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "files.download(tflite_model_file)\n",
        "files.download('labels.txt')\n",
        "\n",
        "!zip -r ./PornRecognition.zip ./saved_model\n",
        "files.download('./PornRecognition2.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZWPcmKWO303"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_acc(history):\n",
        "  '''Plots the training and validation loss and accuracy from a history object'''\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnyRnwopT5aW"
      },
      "outputs": [],
      "source": [
        "# Plot the results of training with data augmentation\n",
        "plot_loss_acc(history_with_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4B9b6GPnKg1"
      },
      "source": [
        "## Check the model\n",
        "\n",
        "This block code is to check if the created model has the expected result "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "extract_dataset('./PornRecognition.zip')"
      ],
      "metadata": {
        "id": "_RPGBMwMAwBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('./myModel')"
      ],
      "metadata": {
        "id": "Jlvlc2NMAXe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbaZqqQv-KYD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ab05d35f-b3ec-4645-b75f-b351277f47b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e6539ad-0fe8-44dd-b9b4-c96f5baedaa7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e6539ad-0fe8-44dd-b9b4-c96f5baedaa7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving prefix_GantMan_0005AA0D-22DE-4DF3-8447-108E30974315.jpg.jpeg to prefix_GantMan_0005AA0D-22DE-4DF3-8447-108E30974315.jpg.jpeg\n",
            "Saving prefix_GantMan_0005E2D3-A7D7-4CDA-AB8D-20BA7FD5E093.jpg.jpeg to prefix_GantMan_0005E2D3-A7D7-4CDA-AB8D-20BA7FD5E093.jpg.jpeg\n",
            "Saving prefix_GantMan_000692EA-5A12-4D17-9CC2-75B59DD7DB2B.jpg.jpeg to prefix_GantMan_000692EA-5A12-4D17-9CC2-75B59DD7DB2B.jpg.jpeg\n",
            "Saving prefix_GantMan_0006B35A-6AC5-4EB0-87F4-16D2F2FE37CC.jpg.jpeg to prefix_GantMan_0006B35A-6AC5-4EB0-87F4-16D2F2FE37CC.jpg.jpeg\n",
            "[0.6694779]\n",
            "prefix_GantMan_0005AA0D-22DE-4DF3-8447-108E30974315.jpg.jpeg is a porn\n",
            "[0.7666305]\n",
            "prefix_GantMan_0005E2D3-A7D7-4CDA-AB8D-20BA7FD5E093.jpg.jpeg is a porn\n",
            "[0.5902504]\n",
            "prefix_GantMan_000692EA-5A12-4D17-9CC2-75B59DD7DB2B.jpg.jpeg is a porn\n",
            "[0.9633449]\n",
            "prefix_GantMan_0006B35A-6AC5-4EB0-87F4-16D2F2FE37CC.jpg.jpeg is a porn\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='./' + fn\n",
        "  img=image.load_img(path, target_size=(150, 150))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x /= 255\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a porn\")\n",
        "  else:\n",
        "    print(fn + \" is not a porn\")\n",
        " "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Porn Detector Part II.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}